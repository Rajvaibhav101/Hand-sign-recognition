{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand-sign recognition",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ6qlJMlYRrx"
      },
      "source": [
        "import numpy as np # We'll be storing our data as numpy arrays\n",
        "import os # For handling directories\n",
        "from PIL import Image # For handling the images\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg # Plotting"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "QlFuNr6BYaIj",
        "outputId": "84e3fe48-5278-47bd-d426-f2ca027e07fe"
      },
      "source": [
        "lookup = dict()\n",
        "reverselookup = dict()\n",
        "count = 0\n",
        "for j in os.listdir('../input/leapgestrecog/leapGestRecog/00/'):\n",
        "    if not j.startswith('.'): # If running this code locally, this is to \n",
        "                              # ensure you aren't reading in hidden folders\n",
        "        lookup[j] = count\n",
        "        reverselookup[count] = j\n",
        "        count = count + 1\n",
        "lookup"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-97ef55d93ba4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mreverselookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/leapgestrecog/leapGestRecog/00/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# If running this code locally, this is to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0;31m# ensure you aren't reading in hidden folders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/leapgestrecog/leapGestRecog/00/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__OnMnFfYdSO"
      },
      "source": [
        "Intro\n",
        "The Hand Gesture Recognition Database is a collection of near-infra-red images of ten distinct hand gestures. In this notebook we use end-to-end deep learning to build a classifier for these images.\n",
        "\n",
        "We'll first load some packages required for reading in and plotting the images.\n",
        "\n",
        "import numpy as np # We'll be storing our data as numpy arrays\n",
        "import os # For handling directories\n",
        "from PIL import Image # For handling the images\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg # Plotting\n",
        "As described in the Data Overview, there are 10 folders labelled 00 to 09, each containing images from a given subject. In each folder there are subfolders for each gesture. We'll build a dictionary lookup storing the names of the gestures we need to identify, and giving each gesture a numerical identifier. We'll also build a dictionary reverselookup that tells us what gesture is associated to a given identifier.\n",
        "\n",
        "lookup = dict()\n",
        "reverselookup = dict()\n",
        "count = 0\n",
        "for j in os.listdir('../input/leapgestrecog/leapGestRecog/00/'):\n",
        "    if not j.startswith('.'): # If running this code locally, this is to \n",
        "                              # ensure you aren't reading in hidden folders\n",
        "        lookup[j] = count\n",
        "        reverselookup[count] = j\n",
        "        count = count + 1\n",
        "lookup\n",
        "{'01_palm': 0,\n",
        " '02_l': 2,\n",
        " '03_fist': 7,\n",
        " '04_fist_moved': 9,\n",
        " '05_thumb': 6,\n",
        " '06_index': 4,\n",
        " '07_ok': 1,\n",
        " '08_palm_moved': 3,\n",
        " '09_c': 8,\n",
        " '10_down': 5}\n",
        "Next we read in the images, storing them in x_data. We store the numerical classifier for each image in y_data. Since the images are quite large and are coming from an infra-red sensor, there's nothing really lost in converting them to greyscale and resizing to speed up the computations.\n",
        "\n",
        "x_data = []\n",
        "y_data = []\n",
        "datacount = 0 # We'll use this to tally how many images are in our dataset\n",
        "for i in range(0, 10): # Loop over the ten top-level folders\n",
        "    for j in os.listdir('../input/leapgestrecog/leapGestRecog/0' + str(i) + '/'):\n",
        "        if not j.startswith('.'): # Again avoid hidden folders\n",
        "            count = 0 # To tally images of a given gesture\n",
        "            for k in os.listdir('../input/leapgestrecog/leapGestRecog/0' + \n",
        "                                str(i) + '/' + j + '/'):\n",
        "                                # Loop over the images\n",
        "                img = Image.open('../input/leapgestrecog/leapGestRecog/0' + \n",
        "                                 str(i) + '/' + j + '/' + k).convert('L')\n",
        "                                # Read in and convert to greyscale\n",
        "                img = img.resize((320, 120))\n",
        "                arr = np.array(img)\n",
        "                x_data.append(arr) \n",
        "                count = count + 1\n",
        "            y_values = np.full((count, 1), lookup[j]) \n",
        "            y_data.append(y_values)\n",
        "            datacount = datacount + count\n",
        "x_data = np.array(x_data, dtype = 'float32')\n",
        "y_data = np.array(y_data)\n",
        "y_data = y_data.reshape(datacount, 1) # Reshape to be the correct size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kkWZ6F5YrlX"
      },
      "source": [
        "from random import randint\n",
        "for i in range(0, 10):\n",
        "    plt.imshow(x_data[i*200 , :, :])\n",
        "    plt.title(reverselookup[y_data[i*200 ,0]])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoH6J_gOYyy5"
      },
      "source": [
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "y_data = to_categorical(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivpyKV7bY2Mw"
      },
      "source": [
        "x_data = x_data.reshape((datacount, 120, 320, 1))\n",
        "x_data /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIl5AtiJY8DM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_further,y_train,y_further = train_test_split(x_data,y_data,test_size = 0.2)\n",
        "x_validate,x_test,y_validate,y_test = train_test_split(x_further,y_further,test_size = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWRAXyPJY-aM"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ68MhiZZBVS"
      },
      "source": [
        "model=models.Sequential()\n",
        "model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', input_shape=(120, 320,1))) \n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu')) \n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1PQr5biZDoL"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=64, verbose=1, validation_data=(x_validate, y_validate))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rh147y-ZGu9"
      },
      "source": [
        "[loss, acc] = model.evaluate(x_test,y_test,verbose=1)\n",
        "print(\"Accuracy:\" + str(acc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}